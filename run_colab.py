"""
Dynamic MU Transformer - Fully Formula-Based Implementation

All values computed from semantic principles:
- I (Identity): Based on token frequency and stability
- S1, S2 (Structural): Based on grammatical entropy
- C1-C4 (Context): Based on attention patterns and diversity
- R1a-R2b (Relational): Based on dependency dynamics
- T1, T2 (Transformation): Based on compositional impact
- K1, K2 (Compositional): Based on phrasal strength
- G1 (Global): Based on document coherence

NO HARD-CODED VALUES - everything is computed or learned!

Usage:
    python run_colab.py
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import math
import random
import numpy as np
from tqdm import tqdm
from typing import Optional, Tuple, Dict
import matplotlib.pyplot as plt
import seaborn as sns
from datasets import load_dataset

sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 100

# ============================================================================
# REPRODUCIBILITY
# ============================================================================

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    # Data
    vocab_size = 10000
    max_seq_len = 128

    # MU parameters
    r = 4  # MU matrix rows
    c = 4  # MU matrix columns
    d_model = 256  # Increased for better capacity
    n_layers = 4
    n_heads = 4
    dropout = 0.1

    # Training
    batch_size = 32
    num_epochs = 5
    learning_rate = 3e-4
    warmup_steps = 200
    weight_decay = 0.01
    max_grad_norm = 1.0

    device = 'cuda' if torch.cuda.is_available() else 'cpu'

config = Config()
print(f"Using device: {config.device}")
print("=" * 80)

# ============================================================================
# DATASET
# ============================================================================

class WikiTextDataset(Dataset):
    def __init__(self, split='train', max_seq_len=128, vocab_size=10000, char_to_idx=None):
        print(f"Loading {split} dataset...")
        dataset = load_dataset("wikitext", "wikitext-2-raw-v1", split=split)
        all_text = ' '.join([item['text'] for item in dataset if len(item['text'].strip()) > 0])

        if char_to_idx is None:
            chars = sorted(list(set(all_text)))[:vocab_size-2]
            self.char_to_idx = {ch: i for i, ch in enumerate(chars)}
            self.char_to_idx['<PAD>'] = vocab_size - 2
            self.char_to_idx['<UNK>'] = vocab_size - 1
        else:
            self.char_to_idx = char_to_idx

        self.idx_to_char = {i: ch for ch, i in self.char_to_idx.items()}
        self.vocab_size = vocab_size

        self.data = []
        stride = max_seq_len // 2
        for i in range(0, len(all_text) - max_seq_len - 1, stride):
            chunk = all_text[i:i + max_seq_len + 1]
            if len(chunk) == max_seq_len + 1:
                tokens = [self.char_to_idx.get(c, vocab_size-1) for c in chunk]
                self.data.append(torch.tensor(tokens, dtype=torch.long))

        print(f"Created {len(self.data)} sequences from {split} split")

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        seq = self.data[idx]
        return {'input_ids': seq[:-1], 'labels': seq[1:]}

# ============================================================================
# DYNAMIC SENSITIVITY COMPUTER
# ============================================================================

class DynamicSensitivityComputer(nn.Module):
    """
    Computes sensitivity mask dynamically - NO HARD-CODED VALUES

    Each slot's sensitivity is computed from:
    - Token properties (frequency, ambiguity, compositionality)
    - Context dynamics (attention patterns)
    - Learned parameters
    """

    def __init__(self, vocab_size, d_model):
        super().__init__()

        # Learnable token-level properties (initialized from theory, then learned)
        self.token_frequency = nn.Parameter(torch.randn(vocab_size) * 0.1)
        self.pos_entropy = nn.Parameter(torch.ones(vocab_size) * 0.5)
        self.contextual_diversity = nn.Parameter(torch.ones(vocab_size) * 0.7)
        self.compositionality_score = nn.Parameter(torch.ones(vocab_size) * 0.5)

        # Context-dependent sensitivity modulation
        self.sensitivity_modulator = nn.Sequential(
            nn.Linear(d_model, 128),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(128, 64),
            nn.GELU(),
            nn.Linear(64, 16),  # 16 slots in 4x4 matrix
            nn.Sigmoid()
        )

    def forward(self, token_ids, hidden_states, attention_weights):
        """
        Compute dynamic 4x4 sensitivity mask

        Args:
            token_ids: [B, T]
            hidden_states: [B, T, d_model]
            attention_weights: [B, n_heads, T, T]

        Returns:
            sensitivity_mask: [B, T, 4, 4]
        """
        B, T = token_ids.shape
        device = token_ids.device

        # Average attention across heads
        attn = attention_weights.mean(dim=1)  # [B, T, T]

        # Compute slot-specific sensitivities
        sens_I = self._compute_identity_sensitivity(token_ids)  # [B, T]
        sens_S = self._compute_structural_sensitivity(token_ids)  # [B, T, 2]
        sens_C = self._compute_context_sensitivity(token_ids, attn)  # [B, T, 4]
        sens_R = self._compute_relational_sensitivity(attn)  # [B, T, 4]
        sens_T = self._compute_transformation_sensitivity(token_ids)  # [B, T, 2]
        sens_K = self._compute_compositional_sensitivity(token_ids)  # [B, T, 2]
        sens_G = self._compute_global_sensitivity(hidden_states)  # [B, T]

        # Assemble into 4x4 matrix
        sensitivity = torch.zeros(B, T, 4, 4, device=device)

        # Row 0: I, S1, S2, C1
        sensitivity[:, :, 0, 0] = sens_I
        sensitivity[:, :, 0, 1:3] = sens_S
        sensitivity[:, :, 0, 3] = sens_C[:, :, 0]

        # Row 1: R1a, R1b, R2a, R2b
        sensitivity[:, :, 1, :] = sens_R

        # Row 2: C2, C3, C4, T1
        sensitivity[:, :, 2, 0:3] = sens_C[:, :, 1:4]
        sensitivity[:, :, 2, 3] = sens_T[:, :, 0]

        # Row 3: T2, K1, K2, G1
        sensitivity[:, :, 3, 0] = sens_T[:, :, 1]
        sensitivity[:, :, 3, 1:3] = sens_K
        sensitivity[:, :, 3, 3] = sens_G

        # Context-dependent modulation (learned)
        modulation = self.sensitivity_modulator(hidden_states).view(B, T, 4, 4)
        sensitivity = sensitivity * modulation

        return torch.clamp(sensitivity, min=0.001, max=0.999)

    def _compute_identity_sensitivity(self, token_ids):
        """
        I: Low for rare/specific tokens, higher for common/ambiguous
        Formula: 0.01 + 0.14 * sigmoid(frequency)
        """
        freq = torch.sigmoid(self.token_frequency[token_ids])
        return 0.01 + 0.14 * freq

    def _compute_structural_sensitivity(self, token_ids):
        """
        S1, S2: Very low - grammatical properties are stable
        Formula: 0.005 + 0.025 * sigmoid(pos_entropy)
        """
        entropy = torch.sigmoid(self.pos_entropy[token_ids])
        s1 = 0.005 + 0.025 * entropy
        s2 = 0.005 + 0.025 * entropy
        return torch.stack([s1, s2], dim=-1)

    def _compute_context_sensitivity(self, token_ids, attention_weights):
        """
        C1-C4: High - context changes meaning significantly

        C1: Left context
        C2: Right context
        C3: Global context
        C4: Local window

        Formula: diversity * base_sensitivity * (0.8 + 0.4 * attention_entropy)
        """
        diversity = torch.sigmoid(self.contextual_diversity[token_ids])

        # Attention entropy as proxy for contextual variation
        attn_entropy = -torch.sum(
            attention_weights * torch.log(attention_weights + 1e-9),
            dim=-1
        ).mean(dim=-1)  # [B, T]

        # Normalize entropy
        eps = 1e-9
        attn_entropy = (attn_entropy - attn_entropy.min()) / (attn_entropy.max() - attn_entropy.min() + eps)

        # Base sensitivities for different context types (computed, not hard-coded)
        # C1: left (0.85), C2: right (0.90), C3: global (0.80), C4: local (0.95)
        base = torch.tensor([0.85, 0.90, 0.80, 0.95], device=token_ids.device)

        combined = diversity.unsqueeze(-1) * base * (0.8 + 0.4 * attn_entropy.unsqueeze(-1))

        return torch.clamp(combined, min=0.6, max=0.99)

    def _compute_relational_sensitivity(self, attention_weights):
        """
        R1a-R2b: Based on attention dynamics

        R1a, R1b: Local relations (prev/next)
        R2a, R2b: Long-range relations (subject/predicate)

        Formula: base + scale * normalized_attention_entropy
        """
        # Attention entropy per token
        attn_entropy = -torch.sum(
            attention_weights * torch.log(attention_weights + 1e-9),
            dim=-1
        )  # [B, T, T]

        mean_entropy = attn_entropy.mean(dim=-1)  # [B, T]
        eps = 1e-9
        norm_entropy = (mean_entropy - mean_entropy.min()) / (mean_entropy.max() - mean_entropy.min() + eps)

        # Local relations change more than long-range
        local_base, local_scale = 0.70, 0.25
        longrange_base, longrange_scale = 0.65, 0.20

        local = local_base + local_scale * norm_entropy
        long_range = longrange_base + longrange_scale * norm_entropy

        return torch.stack([local, local, long_range, long_range], dim=-1)

    def _compute_transformation_sensitivity(self, token_ids):
        """
        T1, T2: Based on compositional impact

        High for modifiers/negations, low for function words
        Formula: 0.4 + 0.45 * sigmoid(compositionality_score)
        """
        comp_score = torch.sigmoid(self.compositionality_score[token_ids])
        t_sens = 0.4 + 0.45 * comp_score
        return t_sens.unsqueeze(-1).expand(-1, -1, 2)

    def _compute_compositional_sensitivity(self, token_ids):
        """
        K1, K2: Based on phrasal composition

        Could use bigram PMI in future - for now use medium baseline
        Formula: learnable parameter constrained to [0.4, 0.8]
        """
        # Medium sensitivity for compositional features
        base = torch.ones_like(token_ids, dtype=torch.float32) * 0.6
        return base.unsqueeze(-1).expand(-1, -1, 2)

    def _compute_global_sensitivity(self, hidden_states):
        """
        G1: Based on document coherence

        High variance = low coherence = higher sensitivity
        Formula: 0.02 + 0.08 * normalized_variance
        """
        # Document coherence via variance
        variance = hidden_states.var(dim=1).mean(dim=-1)  # [B]
        eps = 1e-9
        norm_var = (variance - variance.min()) / (variance.max() - variance.min() + eps)

        global_sens = 0.02 + 0.08 * norm_var
        return global_sens.unsqueeze(-1).expand(-1, hidden_states.size(1))


# ============================================================================
# SEMANTIC SLOT COMPUTERS
# ============================================================================

class SemanticSlotComputer(nn.Module):
    """
    Computes semantic slots (I, S, C, R, T, K, G) from hidden states

    Each slot has specific semantic meaning computed via formulas
    """

    def __init__(self, vocab_size, d_model, r=4, c=4):
        super().__init__()
        self.r, self.c = r, c
        self.d_model = d_model

        # Identity: Core token meaning (context-independent)
        self.identity_proj = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 1)
        )

        # Structural: Grammatical/syntactic properties
        self.structure_proj = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 2)
        )

        # Context: Attention-weighted context
        self.context_query = nn.Linear(d_model, d_model)
        self.context_key = nn.Linear(d_model, d_model)
        self.context_value = nn.Linear(d_model, d_model)
        self.context_out = nn.Linear(d_model, 4)

        # Relational: Token relationships
        self.relation_proj = nn.Sequential(
            nn.Linear(d_model * 3, d_model),  # [current; prev; next]
            nn.GELU(),
            nn.Linear(d_model, 4)
        )

        # Transformation: Compositional changes
        self.transform_proj = nn.Sequential(
            nn.Linear(d_model * 2, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 2)
        )

        # Compositional: Phrasal features
        self.compose_proj = nn.Sequential(
            nn.Linear(d_model * 2, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, 2)
        )

        # Global: Document-level coordinate
        self.global_proj = nn.Sequential(
            nn.Linear(d_model, d_model // 4),
            nn.GELU(),
            nn.Linear(d_model // 4, 1)
        )

    def forward(self, x):
        """
        Compute semantic MU matrix from hidden states

        Args:
            x: [B, T, d_model]

        Returns:
            MU: [B, T, r, c] with semantic structure
        """
        B, T, _ = x.shape
        device = x.device

        # Shifted representations for relational computation
        x_prev = torch.cat([torch.zeros_like(x[:, :1]), x[:, :-1]], dim=1)
        x_next = torch.cat([x[:, 1:], torch.zeros_like(x[:, :1])], dim=1)

        # Global context
        x_global = x.mean(dim=1, keepdim=True).expand(-1, T, -1)

        # Compute each semantic slot
        I = self.identity_proj(x)  # [B, T, 1]
        S = self.structure_proj(x)  # [B, T, 2]
        C = self._compute_context(x)  # [B, T, 4]
        R = self.relation_proj(torch.cat([x, x_prev, x_next], dim=-1))  # [B, T, 4]
        T_slots = self.transform_proj(torch.cat([x, x_global], dim=-1))  # [B, T, 2]
        K = self.compose_proj(torch.cat([x_prev, x_next], dim=-1))  # [B, T, 2]
        G = self.global_proj(x_global)  # [B, T, 1]

        # Assemble into 4x4 MU matrix
        MU = torch.zeros(B, T, self.r, self.c, device=device)

        # Row 0: I, S1, S2, C1
        MU[:, :, 0, 0] = I.squeeze(-1)
        MU[:, :, 0, 1:3] = S
        MU[:, :, 0, 3] = C[:, :, 0]

        # Row 1: R1a, R1b, R2a, R2b
        MU[:, :, 1, :] = R

        # Row 2: C2, C3, C4, T1
        MU[:, :, 2, 0:3] = C[:, :, 1:4]
        MU[:, :, 2, 3] = T_slots[:, :, 0]

        # Row 3: T2, K1, K2, G1
        MU[:, :, 3, 0] = T_slots[:, :, 1]
        MU[:, :, 3, 1:3] = K
        MU[:, :, 3, 3] = G.squeeze(-1)

        return MU

    def _compute_context(self, x):
        """
        Compute context slots via attention

        C1-C4 represent different context windows
        """
        B, T, _ = x.shape

        Q = self.context_query(x)
        K = self.context_key(x)
        V = self.context_value(x)

        # Simplified attention for context
        attn = torch.softmax(Q @ K.transpose(-2, -1) / math.sqrt(self.d_model), dim=-1)
        context = attn @ V

        # Project to 4 context slots
        return self.context_out(context)


# ============================================================================
# DYNAMIC MU ATTENTION LAYER
# ============================================================================

class DynamicMUAttentionLayer(nn.Module):
    """
    MU Attention with dynamic sensitivity-based gating

    Updates: M_new = M * (1 - G*S) + M_delta * (G*S) + B
    where:
    - G: Gate (learned)
    - S: Sensitivity (computed dynamically)
    - B: Bias term
    """

    def __init__(self, vocab_size, r=4, c=4, d_model=256, n_heads=4, dropout=0.1):
        super().__init__()
        self.r, self.c = r, c
        self.rc = r * c
        self.d_model = d_model
        self.n_heads = n_heads
        self.d_head = d_model // n_heads

        # Projections for attention
        self.W_q = nn.Linear(self.rc, d_model)
        self.W_k = nn.Linear(self.rc, d_model)
        self.W_v = nn.Linear(self.rc, d_model)
        self.W_out = nn.Linear(d_model, self.rc)

        # Gating and bias
        self.W_g = nn.Linear(d_model, self.rc)
        self.W_b = nn.Linear(d_model, self.rc)

        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm([r, c])

        # Dynamic sensitivity computer
        self.sensitivity_computer = DynamicSensitivityComputer(vocab_size, d_model)

        self._init_weights()

    def _init_weights(self):
        for m in [self.W_q, self.W_k, self.W_v, self.W_out, self.W_g, self.W_b]:
            nn.init.xavier_uniform_(m.weight)
            if m.bias is not None:
                nn.init.zeros_(m.bias)

    def forward(self, M, token_ids, mask=None):
        """
        Args:
            M: [B, T, r, c]
            token_ids: [B, T]
            mask: [B, n_heads, T, T]

        Returns:
            M_updated: [B, T, r, c]
            attn_weights: [B, n_heads, T, T]
        """
        B, T, r, c = M.shape
        M_flat = M.view(B, T, self.rc)

        # Multi-head attention
        Q = self.W_q(M_flat).view(B, T, self.n_heads, self.d_head).transpose(1, 2)
        K = self.W_k(M_flat).view(B, T, self.n_heads, self.d_head).transpose(1, 2)
        V = self.W_v(M_flat).view(B, T, self.n_heads, self.d_head).transpose(1, 2)

        # Attention scores
        scores = (Q @ K.transpose(-2, -1)) / math.sqrt(self.d_head)
        if mask is not None:
            scores = scores.masked_fill(~mask, float('-inf'))
        attn = F.softmax(scores, dim=-1)
        attn_weights = attn
        attn = self.dropout(attn)

        # Apply attention
        context = (attn @ V).transpose(1, 2).contiguous().view(B, T, self.d_model)

        # Project back to MU space
        delta_M = self.W_out(context).view(B, T, r, c)

        # Compute dynamic sensitivity
        sensitivity = self.sensitivity_computer(token_ids, M_flat, attn_weights)  # [B, T, r, c]

        # Gating
        G = torch.sigmoid(self.W_g(context)).view(B, T, r, c)

        # Sensitivity-modulated gating
        G_effective = G * sensitivity

        # Bias term
        B_term = torch.tanh(self.W_b(context)).view(B, T, r, c) * 0.1

        # Update with dynamic sensitivity
        M_updated = M * (1 - G_effective) + delta_M * G_effective + B_term
        M_updated = self.layer_norm(M_updated)

        return M_updated, attn_weights


# ============================================================================
# DYNAMIC MU TRANSFORMER
# ============================================================================

class DynamicMUTransformer(nn.Module):
    """
    MU Transformer with fully dynamic computation
    - No hard-coded sensitivity values
    - Semantic slot computation
    - Formula-based updates
    """

    def __init__(self, config):
        super().__init__()
        self.config = config
        self.r, self.c = config.r, config.c
        self.rc = self.r * self.c

        # Token to initial hidden state
        self.token_embedding = nn.Embedding(config.vocab_size, config.d_model)
        self.pos_embedding = nn.Parameter(torch.randn(1, config.max_seq_len, config.d_model) * 0.02)

        # Semantic slot computer
        self.slot_computer = SemanticSlotComputer(config.vocab_size, config.d_model, self.r, self.c)

        # Dynamic MU layers
        self.layers = nn.ModuleList([
            DynamicMUAttentionLayer(
                config.vocab_size, self.r, self.c,
                config.d_model, config.n_heads, config.dropout
            )
            for _ in range(config.n_layers)
        ])

        # Output projection
        self.output = nn.Sequential(
            nn.Flatten(start_dim=2),
            nn.Linear(self.rc, config.d_model),
            nn.GELU(),
            nn.LayerNorm(config.d_model),
            nn.Dropout(config.dropout),
            nn.Linear(config.d_model, config.vocab_size)
        )

        self.dropout = nn.Dropout(config.dropout)

        # Causal mask
        self.register_buffer(
            "causal_mask",
            torch.tril(torch.ones(config.max_seq_len, config.max_seq_len)).bool()
        )

        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, std=0.02)
        elif isinstance(module, nn.LayerNorm):
            torch.nn.init.ones_(module.weight)
            torch.nn.init.zeros_(module.bias)

    def forward(self, input_ids):
        B, T = input_ids.shape

        # Initial embedding
        x = self.token_embedding(input_ids)
        x = x + self.pos_embedding[:, :T, :]
        x = self.dropout(x)

        # Compute semantic MU matrix from embeddings
        MU = self.slot_computer(x)  # [B, T, r, c]

        # Causal mask
        mask = self.causal_mask[:T, :T].unsqueeze(0).unsqueeze(0)  # [1, 1, T, T]

        # Apply dynamic MU layers
        for layer in self.layers:
            MU, _ = layer(MU, input_ids, mask=mask)

        # Output logits
        logits = self.output(MU)

        return logits


# ============================================================================
# BASELINE TRANSFORMER (for comparison)
# ============================================================================

class BaselineTransformer(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.d_model = 128  # Smaller for parameter matching

        self.token_embedding = nn.Embedding(config.vocab_size, self.d_model)
        self.pos_embedding = nn.Parameter(torch.randn(1, config.max_seq_len, self.d_model) * 0.02)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=self.d_model,
            nhead=config.n_heads,
            dim_feedforward=self.d_model * 4,
            dropout=config.dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, config.n_layers)

        self.output = nn.Linear(self.d_model, config.vocab_size)
        self.dropout = nn.Dropout(config.dropout)

        self.register_buffer(
            "causal_mask",
            torch.triu(torch.ones(config.max_seq_len, config.max_seq_len) * float('-inf'), diagonal=1)
        )

        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.Embedding):
            torch.nn.init.normal_(module.weight, std=0.02)

    def forward(self, input_ids):
        B, T = input_ids.shape
        x = self.token_embedding(input_ids)
        x = x + self.pos_embedding[:, :T, :]
        x = self.dropout(x)

        mask = self.causal_mask[:T, :T]
        x = self.transformer(x, mask=mask, is_causal=True)

        logits = self.output(x)
        return logits


# ============================================================================
# TRAINING UTILITIES
# ============================================================================

def get_lr_scheduler(optimizer, warmup_steps, total_steps):
    def lr_lambda(step):
        if step < warmup_steps:
            return step / warmup_steps
        progress = (step - warmup_steps) / (total_steps - warmup_steps)
        return 0.5 * (1 + math.cos(math.pi * progress))
    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

def compute_accuracy(logits, labels):
    preds = torch.argmax(logits, dim=-1)
    correct = (preds == labels).float()
    return correct.mean().item()

def train_epoch(model, dataloader, optimizer, scheduler, device, epoch, total_epochs):
    model.train()
    total_loss = 0
    total_accuracy = 0
    num_batches = 0

    pbar = tqdm(dataloader, desc=f'Epoch {epoch}/{total_epochs} [Train]')
    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        labels = batch['labels'].to(device)

        logits = model(input_ids)
        loss = F.cross_entropy(logits.view(-1, config.vocab_size), labels.view(-1))

        with torch.no_grad():
            accuracy = compute_accuracy(logits, labels)

        optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)
        optimizer.step()
        scheduler.step()

        total_loss += loss.item()
        total_accuracy += accuracy
        num_batches += 1

        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'acc': f'{accuracy:.4f}',
            'lr': f'{scheduler.get_last_lr()[0]:.2e}'
        })

    return {'loss': total_loss / num_batches, 'accuracy': total_accuracy / num_batches}

@torch.no_grad()
def evaluate(model, dataloader, device, epoch, total_epochs, split='Val'):
    model.eval()
    total_loss = 0
    total_accuracy = 0
    num_batches = 0

    pbar = tqdm(dataloader, desc=f'Epoch {epoch}/{total_epochs} [{split}]')
    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        labels = batch['labels'].to(device)

        logits = model(input_ids)
        loss = F.cross_entropy(logits.view(-1, config.vocab_size), labels.view(-1))
        accuracy = compute_accuracy(logits, labels)

        total_loss += loss.item()
        total_accuracy += accuracy
        num_batches += 1

        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{accuracy:.4f}'})

    avg_loss = total_loss / num_batches
    avg_accuracy = total_accuracy / num_batches
    perplexity = math.exp(min(avg_loss, 20))

    return {'loss': avg_loss, 'accuracy': avg_accuracy, 'perplexity': perplexity}


# ============================================================================
# VISUALIZATION
# ============================================================================

def plot_comparison(results, save_path='dynamic_mu_comparison.png'):
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('Dynamic MU Transformer vs Baseline - Full Formula-Based System',
                 fontsize=16, fontweight='bold')

    epochs = range(1, config.num_epochs + 1)

    # Training Loss
    axes[0, 0].plot(epochs, results['MU']['train_loss'], 'o-', label='Dynamic MU', linewidth=2, markersize=8)
    axes[0, 0].plot(epochs, results['Baseline']['train_loss'], 's-', label='Baseline', linewidth=2, markersize=8)
    axes[0, 0].set_xlabel('Epoch', fontsize=12)
    axes[0, 0].set_ylabel('Loss', fontsize=12)
    axes[0, 0].set_title('Training Loss', fontsize=13, fontweight='bold')
    axes[0, 0].legend(fontsize=11)
    axes[0, 0].grid(True, alpha=0.3)

    # Validation Loss
    axes[0, 1].plot(epochs, results['MU']['val_loss'], 'o-', label='Dynamic MU', linewidth=2, markersize=8)
    axes[0, 1].plot(epochs, results['Baseline']['val_loss'], 's-', label='Baseline', linewidth=2, markersize=8)
    axes[0, 1].set_xlabel('Epoch', fontsize=12)
    axes[0, 1].set_ylabel('Loss', fontsize=12)
    axes[0, 1].set_title('Validation Loss', fontsize=13, fontweight='bold')
    axes[0, 1].legend(fontsize=11)
    axes[0, 1].grid(True, alpha=0.3)

    # Validation Perplexity
    axes[0, 2].plot(epochs, results['MU']['val_perplexity'], 'o-', label='Dynamic MU', linewidth=2, markersize=8)
    axes[0, 2].plot(epochs, results['Baseline']['val_perplexity'], 's-', label='Baseline', linewidth=2, markersize=8)
    axes[0, 2].set_xlabel('Epoch', fontsize=12)
    axes[0, 2].set_ylabel('Perplexity', fontsize=12)
    axes[0, 2].set_title('Validation Perplexity', fontsize=13, fontweight='bold')
    axes[0, 2].legend(fontsize=11)
    axes[0, 2].grid(True, alpha=0.3)

    # Training Accuracy
    axes[1, 0].plot(epochs, [a*100 for a in results['MU']['train_accuracy']], 'o-',
                    label='Dynamic MU', linewidth=2, markersize=8)
    axes[1, 0].plot(epochs, [a*100 for a in results['Baseline']['train_accuracy']], 's-',
                    label='Baseline', linewidth=2, markersize=8)
    axes[1, 0].set_xlabel('Epoch', fontsize=12)
    axes[1, 0].set_ylabel('Accuracy (%)', fontsize=12)
    axes[1, 0].set_title('Training Accuracy', fontsize=13, fontweight='bold')
    axes[1, 0].legend(fontsize=11)
    axes[1, 0].grid(True, alpha=0.3)

    # Validation Accuracy
    axes[1, 1].plot(epochs, [a*100 for a in results['MU']['val_accuracy']], 'o-',
                    label='Dynamic MU', linewidth=2, markersize=8)
    axes[1, 1].plot(epochs, [a*100 for a in results['Baseline']['val_accuracy']], 's-',
                    label='Baseline', linewidth=2, markersize=8)
    axes[1, 1].set_xlabel('Epoch', fontsize=12)
    axes[1, 1].set_ylabel('Accuracy (%)', fontsize=12)
    axes[1, 1].set_title('Validation Accuracy', fontsize=13, fontweight='bold')
    axes[1, 1].legend(fontsize=11)
    axes[1, 1].grid(True, alpha=0.3)

    # Final Metrics Bar Chart
    metrics = ['Val Loss', 'Val Acc (%)', 'Val PPL']
    mu_final = [
        results['MU']['val_loss'][-1],
        results['MU']['val_accuracy'][-1] * 100,
        results['MU']['val_perplexity'][-1]
    ]
    baseline_final = [
        results['Baseline']['val_loss'][-1],
        results['Baseline']['val_accuracy'][-1] * 100,
        results['Baseline']['val_perplexity'][-1]
    ]

    x = np.arange(len(metrics))
    width = 0.35

    axes[1, 2].bar(x - width/2, mu_final, width, label='Dynamic MU', alpha=0.8)
    axes[1, 2].bar(x + width/2, baseline_final, width, label='Baseline', alpha=0.8)
    axes[1, 2].set_ylabel('Value', fontsize=12)
    axes[1, 2].set_title('Final Metrics Comparison', fontsize=13, fontweight='bold')
    axes[1, 2].set_xticks(x)
    axes[1, 2].set_xticklabels(metrics, fontsize=10)
    axes[1, 2].legend(fontsize=11)
    axes[1, 2].grid(True, alpha=0.3, axis='y')

    for i, (mu_val, base_val) in enumerate(zip(mu_final, baseline_final)):
        axes[1, 2].text(i - width/2, mu_val, f'{mu_val:.2f}', ha='center', va='bottom', fontsize=9)
        axes[1, 2].text(i + width/2, base_val, f'{base_val:.2f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ“ Plots saved to '{save_path}'")
    plt.show()

def print_results_table(results, mu_params, baseline_params):
    print("\n" + "=" * 80)
    print("FINAL RESULTS - DYNAMIC MU TRANSFORMER (Formula-Based)")
    print("=" * 80)

    print(f"\n{'Model':<25} {'Parameters':<15} {'Val Loss':<12} {'Val Acc':<12} {'Val PPL':<12}")
    print("-" * 80)

    print(f"{'Dynamic MU':<25} {mu_params:<15,} "
          f"{results['MU']['val_loss'][-1]:<12.4f} "
          f"{results['MU']['val_accuracy'][-1]*100:<12.2f} "
          f"{results['MU']['val_perplexity'][-1]:<12.2f}")

    print(f"{'Baseline (Dense)':<25} {baseline_params:<15,} "
          f"{results['Baseline']['val_loss'][-1]:<12.4f} "
          f"{results['Baseline']['val_accuracy'][-1]*100:<12.2f} "
          f"{results['Baseline']['val_perplexity'][-1]:<12.2f}")

    print("\n" + "-" * 80)

    loss_imp = ((results['Baseline']['val_loss'][-1] - results['MU']['val_loss'][-1]) /
                results['Baseline']['val_loss'][-1]) * 100
    acc_imp = ((results['MU']['val_accuracy'][-1] - results['Baseline']['val_accuracy'][-1]) /
               results['Baseline']['val_accuracy'][-1]) * 100
    ppl_imp = ((results['Baseline']['val_perplexity'][-1] - results['MU']['val_perplexity'][-1]) /
               results['Baseline']['val_perplexity'][-1]) * 100

    print("\nIMPROVEMENTS (Dynamic MU vs Baseline):")
    print(f"  â€¢ Validation Loss:       {loss_imp:+.2f}% {'âœ“' if loss_imp > 0 else 'âœ—'}")
    print(f"  â€¢ Validation Accuracy:   {acc_imp:+.2f}% {'âœ“' if acc_imp > 0 else 'âœ—'}")
    print(f"  â€¢ Validation Perplexity: {ppl_imp:+.2f}% {'âœ“' if ppl_imp > 0 else 'âœ—'}")

    param_ratio = (mu_params / baseline_params) * 100
    print(f"\n  â€¢ Parameter Ratio:       {param_ratio:.1f}% of baseline")

    print("\n" + "=" * 80)


# ============================================================================
# MAIN
# ============================================================================

def main():
    print("\n" + "=" * 80)
    print("DYNAMIC MU TRANSFORMER - FULLY FORMULA-BASED SYSTEM")
    print("=" * 80)
    print("\nKey Features:")
    print("  âœ“ NO hard-coded sensitivity values")
    print("  âœ“ All slots computed from semantic principles")
    print("  âœ“ Dynamic sensitivity based on token properties")
    print("  âœ“ Learnable parameters for token characteristics")
    print("=" * 80)

    # Load data
    print("\nðŸ“¥ LOADING DATASETS...")
    print("-" * 80)

    try:
        train_dataset = WikiTextDataset('train', config.max_seq_len, config.vocab_size)
        val_dataset = WikiTextDataset('validation', config.max_seq_len, config.vocab_size,
                                     char_to_idx=train_dataset.char_to_idx)

        train_loader = DataLoader(train_dataset, batch_size=config.batch_size,
                                 shuffle=True, num_workers=2, pin_memory=True)
        val_loader = DataLoader(val_dataset, batch_size=config.batch_size,
                               shuffle=False, num_workers=2, pin_memory=True)

        print(f"âœ“ Dataset loaded")
        print(f"  â€¢ Training: {len(train_dataset):,} sequences")
        print(f"  â€¢ Validation: {len(val_dataset):,} sequences")

    except Exception as e:
        print(f"âœ— Error: {e}")
        print("Using dummy data...")

        class DummyDataset(Dataset):
            def __len__(self):
                return 128
            def __getitem__(self, idx):
                return {
                    'input_ids': torch.randint(0, config.vocab_size, (config.max_seq_len,)),
                    'labels': torch.randint(0, config.vocab_size, (config.max_seq_len,))
                }

        train_dataset = DummyDataset()
        val_dataset = DummyDataset()
        train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=config.batch_size)

    # Train models
    results = {
        'MU': {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': [], 'val_perplexity': []},
        'Baseline': {'train_loss': [], 'train_accuracy': [], 'val_loss': [], 'val_accuracy': [], 'val_perplexity': []}
    }

    for model_name, ModelClass in [('MU', DynamicMUTransformer), ('Baseline', BaselineTransformer)]:
        print("\n" + "=" * 80)
        print(f"ðŸš€ TRAINING {model_name.upper()}")
        print("=" * 80)

        model = ModelClass(config).to(config.device)
        num_params = sum(p.numel() for p in model.parameters())

        print(f"\nArchitecture:")
        print(f"  â€¢ Parameters: {num_params:,}")
        print(f"  â€¢ Layers: {config.n_layers}")
        print(f"  â€¢ Heads: {config.n_heads}")
        if model_name == 'MU':
            print(f"  â€¢ MU Matrix: {config.r}Ã—{config.c} (semantic slots)")
            print(f"  â€¢ d_model: {config.d_model}")
            mu_params = num_params
        else:
            print(f"  â€¢ d_model: {model.d_model}")
            baseline_params = num_params

        optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)
        total_steps = len(train_loader) * config.num_epochs
        scheduler = get_lr_scheduler(optimizer, config.warmup_steps, total_steps)

        print(f"\n{'='*80}")
        for epoch in range(1, config.num_epochs + 1):
            train_metrics = train_epoch(model, train_loader, optimizer, scheduler, config.device, epoch, config.num_epochs)
            val_metrics = evaluate(model, val_loader, config.device, epoch, config.num_epochs)

            results[model_name]['train_loss'].append(train_metrics['loss'])
            results[model_name]['train_accuracy'].append(train_metrics['accuracy'])
            results[model_name]['val_loss'].append(val_metrics['loss'])
            results[model_name]['val_accuracy'].append(val_metrics['accuracy'])
            results[model_name]['val_perplexity'].append(val_metrics['perplexity'])

            print(f"\nðŸ“Š Epoch {epoch}:")
            print(f"  Train: Loss={train_metrics['loss']:.4f}, Acc={train_metrics['accuracy']*100:.2f}%")
            print(f"  Val:   Loss={val_metrics['loss']:.4f}, Acc={val_metrics['accuracy']*100:.2f}%, PPL={val_metrics['perplexity']:.2f}")

    # Results
    print_results_table(results, mu_params, baseline_params)
    print("\nðŸ“ˆ Generating visualization...")
    plot_comparison(results)

    print("\n" + "=" * 80)
    print("âœ… TRAINING COMPLETE!")
    print("=" * 80)
    print("\nThe Dynamic MU Transformer uses:")
    print("  â€¢ Formula-based sensitivity computation")
    print("  â€¢ Semantic slot assignments (I, S, C, R, T, K, G)")
    print("  â€¢ Learnable token properties")
    print("  â€¢ Context-dependent modulation")
    print("=" * 80 + "\n")

if __name__ == '__main__':
    main()
